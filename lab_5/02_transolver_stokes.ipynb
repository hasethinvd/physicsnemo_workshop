{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Notebook 2: Training PhysicsNeMo Transolver on Stokes Flow\n",
        "\n",
        "**Goal:** Train a Transolver model and visualize how it learns to partition the mesh into physics-based slices.\n",
        "\n",
        "This notebook follows the same structure as PhysicsNeMo examples (see `examples/cfd/darcy_transolver`).\n",
        "\n",
        "## Outline\n",
        "1. Load Configuration & Dataset\n",
        "2. Create PhysicsNeMo Transolver Model\n",
        "3. Training Loop (following PhysicsNeMo patterns)\n",
        "4. Visualize Learned Slice Assignments\n",
        "\n",
        "**For production training**, use the script:\n",
        "```bash\n",
        "python train_transolver_stokes.py\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from omegaconf import OmegaConf\n",
        "\n",
        "from utils import download_stokes_dataset, load_stokes_sample, get_num_samples\n",
        "\n",
        "# Load configuration (PhysicsNeMo uses OmegaConf/Hydra)\n",
        "cfg = OmegaConf.load(\"conf/config.yaml\")\n",
        "\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "print(f\"Using device: {device}\")\n",
        "print(f\"\\nModel config:\")\n",
        "print(f\"  n_hidden: {cfg.model.n_hidden}, n_layers: {cfg.model.n_layers}\")\n",
        "print(f\"  n_head: {cfg.model.n_head}, slice_num: {cfg.model.slice_num}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load Stokes Flow Dataset\n",
        "\n",
        "We'll use the same dataset from Lab 2: Stokes flow around obstacles with varying geometries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download and load dataset\n",
        "download_stokes_dataset()\n",
        "\n",
        "# Load samples (num from config)\n",
        "total_available = get_num_samples()\n",
        "num_samples = min(cfg.training.num_samples, total_available)\n",
        "print(f\"Loading {num_samples} samples (config: {cfg.training.num_samples}, available: {total_available})...\")\n",
        "\n",
        "train_data = []\n",
        "for i in range(num_samples):\n",
        "    coords, u, v, p = load_stokes_sample(sample_idx=i)\n",
        "    train_data.append({\n",
        "        'coords': torch.tensor(coords, dtype=torch.float32),\n",
        "        'targets': torch.tensor(np.stack([u, v, p], axis=1), dtype=torch.float32)\n",
        "    })\n",
        "\n",
        "# Use first sample for visualization\n",
        "sample_coords = train_data[0]['coords']\n",
        "sample_targets = train_data[0]['targets']\n",
        "N = len(sample_coords)\n",
        "print(f\"✓ Loaded {num_samples} samples, each with ~{N} mesh points\")\n",
        "print(f\"  Input: coordinates (N, 2)\")\n",
        "print(f\"  Output: u, v, p (N, 3)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. PhysicsNeMo Transolver\n",
        "\n",
        "We'll use PhysicsNeMo's production Transolver and add hooks to capture slice weights for visualization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import PhysicsNeMo Transolver\n",
        "from physicsnemo.models.transolver import Transolver\n",
        "\n",
        "print(\"✓ PhysicsNeMo Transolver imported\")\n",
        "print(f\"  Model config: hidden={cfg.model.n_hidden}, layers={cfg.model.n_layers}\")\n",
        "print(f\"                heads={cfg.model.n_head}, slices={cfg.model.slice_num}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create PhysicsNeMo Transolver model from config (following darcy_transolver example)\n",
        "model = Transolver(\n",
        "    functional_dim=cfg.model.functional_dim,\n",
        "    out_dim=cfg.model.out_dim,\n",
        "    embedding_dim=cfg.model.embedding_dim,\n",
        "    n_layers=cfg.model.n_layers,\n",
        "    n_hidden=cfg.model.n_hidden,\n",
        "    n_head=cfg.model.n_head,\n",
        "    slice_num=cfg.model.slice_num,\n",
        "    dropout=cfg.model.dropout,\n",
        "    mlp_ratio=cfg.model.mlp_ratio,\n",
        "    unified_pos=cfg.model.unified_pos,\n",
        "    structured_shape=cfg.model.structured_shape,\n",
        "    use_te=cfg.model.use_te,\n",
        "    act=cfg.model.act,\n",
        "    time_input=cfg.model.time_input,\n",
        ").to(device)\n",
        "\n",
        "# Storage for captured slice weights\n",
        "captured_slice_weights = {}\n",
        "\n",
        "def capture_slice_weights_hook(module, input, output):\n",
        "    \"\"\"Hook to capture slice weights from PhysicsAttention forward pass.\"\"\"\n",
        "    # The slice weights are computed in compute_slices_from_projections\n",
        "    # We need to access them through the module's internal state\n",
        "    # After forward, we can recompute them from the stored projections\n",
        "    pass\n",
        "\n",
        "# Helper function to get slice weights by running a modified forward pass\n",
        "def get_slice_weights(model, coords):\n",
        "    \"\"\"\n",
        "    Extract slice weights from the first PhysicsAttention layer.\n",
        "    \n",
        "    PhysicsNeMo's Transolver computes slice_weights internally in each block's Attn module.\n",
        "    We access the first block and manually compute slice weights from the projections.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        # Prepare input (PhysicsNeMo expects: fx=functional_input, embedding=spatial_coords)\n",
        "        B, N, _ = coords.shape\n",
        "        fx = torch.zeros(B, N, 0, device=coords.device)  # Empty functional input\n",
        "        embedding = coords  # Coordinates as embeddings\n",
        "        \n",
        "        # Run through preprocessing\n",
        "        fx_combined = torch.cat((embedding, fx), -1)  # (B, N, 2)\n",
        "        h = model.preprocess(fx_combined)  # (B, N, hidden_dim)\n",
        "        \n",
        "        # Get first block's attention module\n",
        "        first_block = model.blocks[0]\n",
        "        attn_module = first_block.Attn\n",
        "        \n",
        "        # Run through LayerNorm\n",
        "        h_normed = first_block.ln_1(h)\n",
        "        \n",
        "        # Project to head dimension (PhysicsNeMo internal)\n",
        "        x_mid = attn_module.in_project_x(h_normed)\n",
        "        x_mid = x_mid.view(B, N, attn_module.heads, attn_module.dim_head)\n",
        "        \n",
        "        # Compute slice projections\n",
        "        slice_projections = attn_module.in_project_slice(x_mid)  # (B, N, heads, slices)\n",
        "        \n",
        "        # Compute slice weights (temperature-scaled softmax)\n",
        "        temp = torch.clamp(attn_module.temperature, min=0.5, max=5)\n",
        "        slice_weights = F.softmax(slice_projections / temp, dim=-1)  # (B, N, heads, slices)\n",
        "        \n",
        "        # Average across heads for visualization\n",
        "        slice_weights_avg = slice_weights.mean(dim=2)  # (B, N, slices)\n",
        "        \n",
        "        return slice_weights_avg\n",
        "\n",
        "n_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"✓ PhysicsNeMo Transolver created: {n_params:,} parameters\")\n",
        "print(f\"  Architecture: {NUM_LAYERS} layers × {NUM_HEADS} heads × {NUM_SLICES} slices\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Training Loop\n",
        "\n",
        "Following PhysicsNeMo training patterns with:\n",
        "- AdamW optimizer with weight decay\n",
        "- StepLR scheduler (decay every N epochs)\n",
        "- Gradient clipping for stability"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training setup from config (following PhysicsNeMo pattern)\n",
        "optimizer = torch.optim.AdamW(\n",
        "    model.parameters(), \n",
        "    lr=cfg.scheduler.initial_lr, \n",
        "    weight_decay=cfg.training.weight_decay\n",
        ")\n",
        "# StepLR scheduler (like PhysicsNeMo examples)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(\n",
        "    optimizer, \n",
        "    step_size=cfg.scheduler.decay_epochs, \n",
        "    gamma=cfg.scheduler.decay_rate\n",
        ")\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "NUM_EPOCHS = cfg.training.epochs\n",
        "GRAD_CLIP = cfg.training.gradient_clip\n",
        "SNAPSHOT_EPOCHS = list(cfg.visualization.snapshot_epochs)\n",
        "\n",
        "losses = []\n",
        "slice_history = []  # Store slice assignments at different epochs\n",
        "\n",
        "# Get initial slice assignments (before training)\n",
        "x = sample_coords.unsqueeze(0).to(device)\n",
        "initial_slices = get_slice_weights(model, x)[0].cpu().numpy()\n",
        "slice_history.append(('Epoch 0 (untrained)', initial_slices))\n",
        "\n",
        "print(f\"Training PhysicsNeMo Transolver on {len(train_data)} samples...\")\n",
        "print(f\"  Epochs: {NUM_EPOCHS}, Initial LR: {cfg.scheduler.initial_lr}\")\n",
        "print(f\"  LR decay: {cfg.scheduler.decay_rate} every {cfg.scheduler.decay_epochs} epochs\")\n",
        "print(f\"  Snapshots at: {SNAPSHOT_EPOCHS}\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    model.train()\n",
        "    epoch_loss = 0.0\n",
        "    \n",
        "    # Shuffle data each epoch\n",
        "    indices = np.random.permutation(len(train_data))\n",
        "    \n",
        "    for idx in indices:\n",
        "        data = train_data[idx]\n",
        "        coords = data['coords'].unsqueeze(0).to(device)\n",
        "        targets = data['targets'].unsqueeze(0).to(device)\n",
        "        \n",
        "        # PhysicsNeMo Transolver forward: fx=functional_input, embedding=coords\n",
        "        optimizer.zero_grad()\n",
        "        B, N, _ = coords.shape\n",
        "        fx = torch.zeros(B, N, 0, device=device)  # Empty functional input\n",
        "        pred = model(fx, embedding=coords)\n",
        "        loss = criterion(pred, targets)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=GRAD_CLIP)\n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "    \n",
        "    scheduler.step()  # Update learning rate\n",
        "    avg_loss = epoch_loss / len(train_data)\n",
        "    losses.append(avg_loss)\n",
        "    \n",
        "    # Save slice assignments at snapshot epochs\n",
        "    if (epoch + 1) in SNAPSHOT_EPOCHS:\n",
        "        x = sample_coords.unsqueeze(0).to(device)\n",
        "        slices = get_slice_weights(model, x)[0].cpu().numpy()\n",
        "        slice_history.append((f'Epoch {epoch+1}', slices))\n",
        "    \n",
        "    if (epoch + 1) % cfg.logging.print_every == 0 or epoch == 0:\n",
        "        lr = optimizer.param_groups[0]['lr']\n",
        "        print(f\"Epoch {epoch+1:3d}/{NUM_EPOCHS}: Loss = {avg_loss:.6f}, LR = {lr:.2e}\")\n",
        "\n",
        "print(\"-\" * 60)\n",
        "print(f\"✓ Training complete! Final loss: {losses[-1]:.6f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary & Key Takeaways\n",
        "\n",
        "Let's see how the model learned to partition the mesh during training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot training loss\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(range(1, NUM_EPOCHS+1), losses, 'b-o', linewidth=2, markersize=4)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('MSE Loss')\n",
        "plt.title('Training Loss')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.semilogy(range(1, NUM_EPOCHS+1), losses, 'b-o', linewidth=2, markersize=4)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('MSE Loss (log scale)')\n",
        "plt.title('Training Loss (Log Scale)')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize how slice assignments evolved during training\n",
        "coords_np = sample_coords.numpy()\n",
        "num_snapshots = len(slice_history)\n",
        "\n",
        "fig, axes = plt.subplots(1, num_snapshots, figsize=(4*num_snapshots, 4))\n",
        "\n",
        "for idx, (title, slice_weights) in enumerate(slice_history):\n",
        "    ax = axes[idx] if num_snapshots > 1 else axes\n",
        "    \n",
        "    # Get dominant slice for each point\n",
        "    dominant_slice = np.argmax(slice_weights, axis=1)\n",
        "    \n",
        "    # Plot mesh colored by slice\n",
        "    scatter = ax.scatter(coords_np[:, 0], coords_np[:, 1], c=dominant_slice, \n",
        "                        cmap='tab10', s=6, alpha=0.7)\n",
        "    ax.set_title(title, fontsize=11)\n",
        "    ax.set_xlabel('x')\n",
        "    ax.set_ylabel('y')\n",
        "    ax.set_aspect('equal')\n",
        "\n",
        "plt.suptitle('Evolution of Learned Slice Assignments During Training', fontsize=12, y=1.02)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Notice how slices become more spatially coherent as training progresses!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Final comparison: Learned slices vs actual physics\n",
        "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
        "\n",
        "# Get final slice assignments\n",
        "final_slices = slice_history[-1][1]\n",
        "dominant_slice = np.argmax(final_slices, axis=1)\n",
        "targets_np = sample_targets.numpy()\n",
        "\n",
        "# Top left: Velocity u\n",
        "ax = axes[0, 0]\n",
        "sc = ax.scatter(coords_np[:, 0], coords_np[:, 1], c=targets_np[:, 0], cmap='RdBu_r', s=6)\n",
        "ax.set_title('Ground Truth: Velocity u', fontsize=11)\n",
        "ax.set_xlabel('x')\n",
        "ax.set_ylabel('y')\n",
        "ax.set_aspect('equal')\n",
        "plt.colorbar(sc, ax=ax, shrink=0.8)\n",
        "\n",
        "# Top right: Velocity v\n",
        "ax = axes[0, 1]\n",
        "sc = ax.scatter(coords_np[:, 0], coords_np[:, 1], c=targets_np[:, 1], cmap='RdBu_r', s=6)\n",
        "ax.set_title('Ground Truth: Velocity v', fontsize=11)\n",
        "ax.set_xlabel('x')\n",
        "ax.set_ylabel('y')\n",
        "ax.set_aspect('equal')\n",
        "plt.colorbar(sc, ax=ax, shrink=0.8)\n",
        "\n",
        "# Bottom left: Pressure\n",
        "ax = axes[1, 0]\n",
        "sc = ax.scatter(coords_np[:, 0], coords_np[:, 1], c=targets_np[:, 2], cmap='viridis', s=6)\n",
        "ax.set_title('Ground Truth: Pressure p', fontsize=11)\n",
        "ax.set_xlabel('x')\n",
        "ax.set_ylabel('y')\n",
        "ax.set_aspect('equal')\n",
        "plt.colorbar(sc, ax=ax, shrink=0.8)\n",
        "\n",
        "# Bottom right: Learned slices\n",
        "ax = axes[1, 1]\n",
        "sc = ax.scatter(coords_np[:, 0], coords_np[:, 1], c=dominant_slice, cmap='tab20', s=6, alpha=0.8)\n",
        "ax.set_title(f'Learned Slice Assignments (M={NUM_SLICES})', fontsize=11)\n",
        "ax.set_xlabel('x')\n",
        "ax.set_ylabel('y')\n",
        "ax.set_aspect('equal')\n",
        "cbar = plt.colorbar(sc, ax=ax, shrink=0.8)\n",
        "cbar.set_label('Slice ID')\n",
        "\n",
        "plt.suptitle('Physics Fields vs Learned Slice Partitioning', fontsize=13, y=1.01)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Show top slices separately\n",
        "print(f\"\\n--- Visualizing top learned slices ---\")\n",
        "slice_counts = [(i, np.sum(dominant_slice == i)) for i in range(NUM_SLICES)]\n",
        "slice_counts.sort(key=lambda x: -x[1])\n",
        "top_slices = [s for s in slice_counts if s[1] > 0][:8]\n",
        "\n",
        "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
        "axes = axes.flatten()\n",
        "cmap = plt.cm.tab20\n",
        "\n",
        "for idx, (slice_id, count) in enumerate(top_slices):\n",
        "    ax = axes[idx]\n",
        "    mask = dominant_slice == slice_id\n",
        "    ax.scatter(coords_np[:, 0], coords_np[:, 1], c='lightgray', s=3, alpha=0.3)\n",
        "    ax.scatter(coords_np[mask, 0], coords_np[mask, 1], c=[cmap(slice_id % 20)], s=8, alpha=0.8)\n",
        "    ax.set_title(f'Slice {slice_id}: {count} pts ({100*count/len(coords_np):.1f}%)', fontsize=10)\n",
        "    ax.set_xlabel('x')\n",
        "    ax.set_ylabel('y')\n",
        "    ax.set_aspect('equal')\n",
        "\n",
        "for idx in range(len(top_slices), 8):\n",
        "    axes[idx].axis('off')\n",
        "\n",
        "plt.suptitle(f'Top {len(top_slices)} Active Slices (of {NUM_SLICES} total)', fontsize=13, y=1.01)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Statistics\n",
        "active_slices = len([s for s in slice_counts if s[1] > 0])\n",
        "print(f\"\\nSlice usage: {active_slices}/{NUM_SLICES} active slices\")\n",
        "print(\"The model learns to group points with similar physical behavior!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "**What we demonstrated:**\n",
        "1. Used **PhysicsNeMo's production Transolver** (`from physicsnemo.models.transolver import Transolver`)\n",
        "2. Trained on Stokes flow data for 200 epochs\n",
        "3. Visualized how **slice assignments evolve** during training\n",
        "\n",
        "**Key observations:**\n",
        "- Initially (untrained): slices are essentially random (diagonal pattern from linear projections)\n",
        "- After training: slices align with physics (e.g., inlet, wake, boundaries)\n",
        "- The model learns to partition the mesh based on **physical behavior**\n",
        "- This learned partitioning enables efficient O(N·M) attention instead of O(N²)"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
