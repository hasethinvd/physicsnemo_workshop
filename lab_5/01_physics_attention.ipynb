{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Notebook 1: Physics-Attention vs Standard Attention\n",
        "\n",
        "**Goal:** Understand why standard transformers are expensive for physics simulations and how Physics-Attention solves this.\n",
        "\n",
        "## Outline\n",
        "1. Load Sample Stokes Flow Data\n",
        "2. The Quadratic Cost Problem\n",
        "3. Physics-Attention: The 4-Step Solution\n",
        "4. Visualize with Real Mesh Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "from utils import softmax, download_stokes_dataset, load_stokes_sample\n",
        "\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Download & Load Stokes Flow Data\n",
        "\n",
        "We'll use the Stokes flow dataset (same as Lab 2). Run the cell below to download if needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download dataset (if not present) and load a sample\n",
        "download_stokes_dataset()\n",
        "coords, u, v, p = load_stokes_sample()\n",
        "N_mesh = len(coords)\n",
        "\n",
        "# Interactive visualization with Plotly\n",
        "fig = make_subplots(rows=1, cols=3, subplot_titles=['Velocity u', 'Velocity v', 'Pressure p'])\n",
        "\n",
        "fig.add_trace(go.Scatter(x=coords[:, 0], y=coords[:, 1], mode='markers',\n",
        "    marker=dict(size=5, color=u, colorscale='RdBu_r', showscale=True, \n",
        "                colorbar=dict(x=0.28, len=0.8, title='u')),\n",
        "    name='u', hovertemplate='x=%{x:.2f}<br>y=%{y:.2f}<br>u=%{marker.color:.3f}'), row=1, col=1)\n",
        "\n",
        "fig.add_trace(go.Scatter(x=coords[:, 0], y=coords[:, 1], mode='markers',\n",
        "    marker=dict(size=5, color=v, colorscale='RdBu_r', showscale=True,\n",
        "                colorbar=dict(x=0.62, len=0.8, title='v')),\n",
        "    name='v', hovertemplate='x=%{x:.2f}<br>y=%{y:.2f}<br>v=%{marker.color:.3f}'), row=1, col=2)\n",
        "\n",
        "fig.add_trace(go.Scatter(x=coords[:, 0], y=coords[:, 1], mode='markers',\n",
        "    marker=dict(size=5, color=p, colorscale='Viridis', showscale=True,\n",
        "                colorbar=dict(x=0.97, len=0.8, title='p')),\n",
        "    name='p', hovertemplate='x=%{x:.2f}<br>y=%{y:.2f}<br>p=%{marker.color:.3f}'), row=1, col=3)\n",
        "\n",
        "fig.update_layout(title=f'Stokes Flow Data (N={N_mesh} mesh points)', height=400, width=1100, showlegend=False)\n",
        "fig.update_xaxes(title_text='x')\n",
        "fig.update_yaxes(title_text='y', scaleanchor='x', scaleratio=1)\n",
        "fig.show()\n",
        "\n",
        "print(f\"✓ Loaded mesh with {N_mesh} points\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. The Quadratic Cost Problem\n",
        "\n",
        "Standard self-attention computes: $\\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d}}\\right)V$\n",
        "\n",
        "The $QK^T$ creates an **N × N** attention matrix — this is expensive for large meshes!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize the cost scaling\n",
        "N = N_mesh  # Use actual mesh size\n",
        "M = 8  # Number of slices\n",
        "\n",
        "mesh_sizes = np.array([N, N*2, N*5, N*10, N*50, N*100])\n",
        "standard_cost = mesh_sizes ** 2  # O(N²)\n",
        "physics_cost = mesh_sizes * M    # O(N·M)\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "# Cost comparison\n",
        "ax1 = axes[0]\n",
        "ax1.loglog(mesh_sizes, standard_cost, 'r-o', label='Standard Attention O(N²)', linewidth=2)\n",
        "ax1.loglog(mesh_sizes, physics_cost, 'g-o', label='Physics-Attention O(N·M)', linewidth=2)\n",
        "ax1.axvline(x=N, color='blue', linestyle='--', alpha=0.5, label=f'Our mesh (N={N})')\n",
        "ax1.set_xlabel('Mesh Points (N)')\n",
        "ax1.set_ylabel('Operations')\n",
        "ax1.set_title('Computational Cost Comparison')\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Show what N×N attention matrix looks like (subsampled)\n",
        "ax2 = axes[1]\n",
        "subsample = min(100, N)\n",
        "std_attn = softmax(np.random.randn(subsample, subsample), axis=1)\n",
        "im = ax2.imshow(std_attn, cmap='Reds', aspect='auto')\n",
        "ax2.set_title(f'Standard Attention Matrix\\n(showing {subsample}×{subsample} of {N}×{N})')\n",
        "ax2.set_xlabel('Key points')\n",
        "ax2.set_ylabel('Query points')\n",
        "plt.colorbar(im, ax=ax2)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nFor our mesh (N={N}):\")\n",
        "print(f\"  Standard Attention: {N}×{N} = {N*N:,} operations\")\n",
        "print(f\"  Physics-Attention:  {N}×{M} = {N*M:,} operations\")\n",
        "print(f\"  Cost reduction: {N*N // (N*M)}x cheaper!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Physics-Attention: The 4-Step Solution\n",
        "\n",
        "Transolver's key insight: **Physics is mostly local**. We can group points into M \"slices\" and attend between slices instead.\n",
        "\n",
        "1. **Slice**: Assign N points to M groups (soft assignment)\n",
        "2. **Aggregate**: Compress each slice into a single token  \n",
        "3. **Attend**: M×M attention between slice tokens (cheap!)\n",
        "4. **Deslice**: Broadcast back to N points"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create physics-based features from our mesh (coords + physics values)\n",
        "C = 8  # Feature dimension\n",
        "features = np.column_stack([\n",
        "    coords,  # x, y coordinates\n",
        "    u.reshape(-1, 1),  # velocity u\n",
        "    v.reshape(-1, 1),  # velocity v  \n",
        "    p.reshape(-1, 1),  # pressure\n",
        "    np.random.randn(N, C-5)  # padding to get C features\n",
        "])\n",
        "\n",
        "# Simulate slice assignment (learned weights in real model)\n",
        "W_slice = np.random.randn(C, M) * 0.5\n",
        "slice_logits = features @ W_slice\n",
        "slice_weights = softmax(slice_logits, axis=1)  # (N, M) - soft assignment\n",
        "\n",
        "# Simulate M×M attention\n",
        "attn_matrix = softmax(np.random.randn(M, M), axis=1)\n",
        "\n",
        "# Visualize the comparison\n",
        "fig, axes = plt.subplots(1, 3, figsize=(14, 4))\n",
        "\n",
        "# Standard attention matrix (subsampled)\n",
        "ax1 = axes[0]\n",
        "subsample = min(80, N)\n",
        "std_attn = softmax(np.random.randn(subsample, subsample), axis=1)\n",
        "im1 = ax1.imshow(std_attn, cmap='Reds')\n",
        "ax1.set_title(f'Standard Attention\\n({N}×{N} = {N*N:,} ops)', fontsize=11)\n",
        "ax1.set_xlabel('Key points')\n",
        "ax1.set_ylabel('Query points')\n",
        "\n",
        "# Slice assignment matrix\n",
        "ax2 = axes[1]\n",
        "# Sort by x-coordinate for visualization\n",
        "sort_idx = np.argsort(coords[:, 0])\n",
        "im2 = ax2.imshow(slice_weights[sort_idx[:200]].T, aspect='auto', cmap='Greens')\n",
        "ax2.set_title('Slice Assignments\\n(N points → M slices)', fontsize=11)\n",
        "ax2.set_xlabel('Mesh points (sorted by x)')\n",
        "ax2.set_ylabel(f'Slices (M={M})')\n",
        "plt.colorbar(im2, ax=ax2)\n",
        "\n",
        "# Physics-Attention: M×M\n",
        "ax3 = axes[2]\n",
        "im3 = ax3.imshow(attn_matrix, cmap='Greens')\n",
        "ax3.set_title(f'Physics-Attention\\n({M}×{M} = {M*M} ops)', fontsize=11)\n",
        "ax3.set_xlabel('Key slices')\n",
        "ax3.set_ylabel('Query slices')\n",
        "plt.colorbar(im3, ax=ax3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"Cost reduction: {N*N:,} → {M*M} = {N*N // (M*M):,}x fewer attention operations!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Visualizing Slices on Our Mesh\n",
        "\n",
        "Let's see how different numbers of slices partition our Stokes flow mesh. The slices learn to group points with similar physical behavior."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Interactive visualization of slice assignments with Plotly\n",
        "slice_counts = [4, 8, 16]\n",
        "fig = make_subplots(rows=1, cols=3, subplot_titles=[f'M = {m} slices' for m in slice_counts])\n",
        "\n",
        "colors_tab10 = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', \n",
        "                '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf',\n",
        "                '#aec7e8', '#ffbb78', '#98df8a', '#ff9896', '#c5b0d5', '#c49c94']\n",
        "\n",
        "for idx, num_slices in enumerate(slice_counts):\n",
        "    # Create slice assignments\n",
        "    W = np.random.randn(C, num_slices) * 0.5\n",
        "    logits = features @ W\n",
        "    weights = softmax(logits, axis=1)\n",
        "    dominant_slice = np.argmax(weights, axis=1)\n",
        "    \n",
        "    # Add traces for each slice\n",
        "    for slice_id in range(num_slices):\n",
        "        mask = dominant_slice == slice_id\n",
        "        if mask.sum() > 0:\n",
        "            fig.add_trace(go.Scatter(\n",
        "                x=coords[mask, 0], y=coords[mask, 1], mode='markers',\n",
        "                marker=dict(size=6, color=colors_tab10[slice_id % len(colors_tab10)]),\n",
        "                name=f'Slice {slice_id}', showlegend=(idx == 0),\n",
        "                hovertemplate=f'Slice {slice_id}<br>x=%{{x:.2f}}<br>y=%{{y:.2f}}'\n",
        "            ), row=1, col=idx+1)\n",
        "\n",
        "fig.update_layout(\n",
        "    title='How Different Slice Counts (M) Partition the Mesh',\n",
        "    height=400, width=1200,\n",
        "    legend=dict(x=1.02, y=0.5)\n",
        ")\n",
        "fig.update_xaxes(title_text='x')\n",
        "fig.update_yaxes(title_text='y', scaleanchor='x', scaleratio=1)\n",
        "fig.show()\n",
        "\n",
        "print(\"Note: In a trained model, slices would group physically similar regions\")\n",
        "print(\"      (e.g., inlet, wake, boundary layers) rather than random partitions.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "| Aspect | Standard Attention | Physics-Attention |\n",
        "|--------|-------------------|-------------------|\n",
        "| **Complexity** | O(N²) — expensive! | O(N·M) — efficient! |\n",
        "| **Attention matrix** | N×N | M×M (M≈64) |\n",
        "| **Grouping** | All-to-all | Learned slices |\n",
        "\n",
        "**Key Takeaway:** Physics-Attention reduces cost by grouping mesh points into M learned \"slices\" and performing attention between these compressed representations.\n",
        "\n",
        "**Next:** Notebook 2 shows the full Transolver architecture in PyTorch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
