{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Notebook 1: Physics-Attention vs Standard Attention\n",
        "\n",
        "**Goal:** Understand why standard transformers are expensive for physics simulations and how Physics-Attention solves this.\n",
        "\n",
        "## Outline\n",
        "1. Load Sample Stokes Flow Data\n",
        "2. The Quadratic Cost Problem\n",
        "3. Physics-Attention: The 4-Step Solution\n",
        "4. Visualize with Real Mesh Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "from utils import softmax, download_stokes_dataset, load_stokes_sample\n",
        "\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Download & Load Stokes Flow Data\n",
        "\n",
        "We'll use the Stokes flow dataset (same as Lab 2). Run the cell below to download if needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download dataset (if not present) and load a sample\n",
        "download_stokes_dataset()\n",
        "coords, u, v, p = load_stokes_sample()\n",
        "N_mesh = len(coords)\n",
        "\n",
        "# Interactive visualization with Plotly\n",
        "fig = make_subplots(rows=1, cols=3, subplot_titles=['Velocity u', 'Velocity v', 'Pressure p'])\n",
        "\n",
        "fig.add_trace(go.Scatter(x=coords[:, 0], y=coords[:, 1], mode='markers',\n",
        "    marker=dict(size=5, color=u, colorscale='RdBu_r', showscale=True, \n",
        "                colorbar=dict(x=0.28, len=0.8, title='u')),\n",
        "    name='u', hovertemplate='x=%{x:.2f}<br>y=%{y:.2f}<br>u=%{marker.color:.3f}'), row=1, col=1)\n",
        "\n",
        "fig.add_trace(go.Scatter(x=coords[:, 0], y=coords[:, 1], mode='markers',\n",
        "    marker=dict(size=5, color=v, colorscale='RdBu_r', showscale=True,\n",
        "                colorbar=dict(x=0.62, len=0.8, title='v')),\n",
        "    name='v', hovertemplate='x=%{x:.2f}<br>y=%{y:.2f}<br>v=%{marker.color:.3f}'), row=1, col=2)\n",
        "\n",
        "fig.add_trace(go.Scatter(x=coords[:, 0], y=coords[:, 1], mode='markers',\n",
        "    marker=dict(size=5, color=p, colorscale='Viridis', showscale=True,\n",
        "                colorbar=dict(x=0.97, len=0.8, title='p')),\n",
        "    name='p', hovertemplate='x=%{x:.2f}<br>y=%{y:.2f}<br>p=%{marker.color:.3f}'), row=1, col=3)\n",
        "\n",
        "fig.update_layout(title=f'Stokes Flow Data (N={N_mesh} mesh points)', height=400, width=1100, showlegend=False)\n",
        "fig.update_xaxes(title_text='x')\n",
        "fig.update_yaxes(title_text='y', scaleanchor='x', scaleratio=1)\n",
        "fig.show()\n",
        "\n",
        "print(f\"✓ Loaded mesh with {N_mesh} points\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. The Quadratic Cost Problem\n",
        "\n",
        "Standard self-attention computes: $\\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d}}\\right)V$\n",
        "\n",
        "The $QK^T$ creates an **N × N** attention matrix — this is expensive for large meshes!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize the cost scaling\n",
        "N = N_mesh  # Use actual mesh size\n",
        "M = 8  # Number of slices\n",
        "\n",
        "mesh_sizes = np.array([N, N*2, N*5, N*10, N*50, N*100])\n",
        "standard_cost = mesh_sizes ** 2  # O(N²)\n",
        "physics_cost = mesh_sizes * M    # O(N·M)\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "# Cost comparison\n",
        "ax1 = axes[0]\n",
        "ax1.loglog(mesh_sizes, standard_cost, 'r-o', label='Standard Attention O(N²)', linewidth=2)\n",
        "ax1.loglog(mesh_sizes, physics_cost, 'g-o', label='Physics-Attention O(N·M)', linewidth=2)\n",
        "ax1.axvline(x=N, color='blue', linestyle='--', alpha=0.5, label=f'Our mesh (N={N})')\n",
        "ax1.set_xlabel('Mesh Points (N)')\n",
        "ax1.set_ylabel('Operations')\n",
        "ax1.set_title('Computational Cost Comparison')\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Show what N×N attention matrix looks like (subsampled)\n",
        "ax2 = axes[1]\n",
        "subsample = min(100, N)\n",
        "std_attn = softmax(np.random.randn(subsample, subsample), axis=1)\n",
        "im = ax2.imshow(std_attn, cmap='Reds', aspect='auto')\n",
        "ax2.set_title(f'Standard Attention Matrix\\n(showing {subsample}×{subsample} of {N}×{N})')\n",
        "ax2.set_xlabel('Key points')\n",
        "ax2.set_ylabel('Query points')\n",
        "plt.colorbar(im, ax=ax2)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nFor our mesh (N={N}):\")\n",
        "print(f\"  Standard Attention: {N}×{N} = {N*N:,} operations\")\n",
        "print(f\"  Physics-Attention:  {N}×{M} = {N*M:,} operations\")\n",
        "print(f\"  Cost reduction: {N*N // (N*M)}x cheaper!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Physics-Attention: The 4-Step Solution\n",
        "\n",
        "### What are \"Slices\"?\n",
        "\n",
        "In physics simulations, different regions of a mesh often have similar physical behavior:\n",
        "- **Inlet region**: Smooth laminar flow\n",
        "- **Obstacle wake**: Turbulent/recirculating flow  \n",
        "- **Boundary layer**: High gradients near walls\n",
        "- **Far-field**: Nearly uniform flow\n",
        "\n",
        "**Slices** are learned groupings that cluster mesh points with similar physics. Instead of every point attending to every other point (N×N), we:\n",
        "1. Group points into M slices (soft assignment via learned weights)\n",
        "2. Compute attention only between slice representations (M×M)\n",
        "\n",
        "### The 4-Step Algorithm\n",
        "\n",
        "```\n",
        "Input: X ∈ R^(N×C)  (N mesh points, C features)\n",
        "       W ∈ R^(C×M)  (learnable slice weights)\n",
        "\n",
        "Step 1 - SLICE:     S = softmax(X @ W)           → S ∈ R^(N×M)  (assignment weights)\n",
        "Step 2 - AGGREGATE: Z = S^T @ X                  → Z ∈ R^(M×C)  (slice tokens)\n",
        "Step 3 - ATTEND:    Z' = Attention(Z, Z, Z)      → Z' ∈ R^(M×C) (M×M attention!)\n",
        "Step 4 - DESLICE:   Y = S @ Z'                   → Y ∈ R^(N×C)  (broadcast back)\n",
        "\n",
        "Output: Y ∈ R^(N×C)\n",
        "```\n",
        "\n",
        "**Key insight:** Step 3 is O(M²) instead of O(N²), and M is typically 8-64 while N can be 10,000+!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create physics-based features from our mesh (coords + physics values)\n",
        "C = 8  # Feature dimension\n",
        "features = np.column_stack([\n",
        "    coords,  # x, y coordinates\n",
        "    u.reshape(-1, 1),  # velocity u\n",
        "    v.reshape(-1, 1),  # velocity v  \n",
        "    p.reshape(-1, 1),  # pressure\n",
        "    np.random.randn(N, C-5)  # padding to get C features\n",
        "])\n",
        "\n",
        "# Simulate slice assignment (learned weights in real model)\n",
        "W_slice = np.random.randn(C, M) * 0.5\n",
        "slice_logits = features @ W_slice\n",
        "slice_weights = softmax(slice_logits, axis=1)  # (N, M) - soft assignment\n",
        "\n",
        "# Simulate M×M attention\n",
        "attn_matrix = softmax(np.random.randn(M, M), axis=1)\n",
        "\n",
        "# Visualize the comparison\n",
        "fig, axes = plt.subplots(1, 3, figsize=(14, 4))\n",
        "\n",
        "# Standard attention matrix (subsampled)\n",
        "ax1 = axes[0]\n",
        "subsample = min(80, N)\n",
        "std_attn = softmax(np.random.randn(subsample, subsample), axis=1)\n",
        "im1 = ax1.imshow(std_attn, cmap='Reds')\n",
        "ax1.set_title(f'Standard Attention\\n({N}×{N} = {N*N:,} ops)', fontsize=11)\n",
        "ax1.set_xlabel('Key points')\n",
        "ax1.set_ylabel('Query points')\n",
        "\n",
        "# Slice assignment matrix\n",
        "ax2 = axes[1]\n",
        "# Sort by x-coordinate for visualization\n",
        "sort_idx = np.argsort(coords[:, 0])\n",
        "im2 = ax2.imshow(slice_weights[sort_idx[:200]].T, aspect='auto', cmap='Greens')\n",
        "ax2.set_title('Slice Assignments\\n(N points → M slices)', fontsize=11)\n",
        "ax2.set_xlabel('Mesh points (sorted by x)')\n",
        "ax2.set_ylabel(f'Slices (M={M})')\n",
        "plt.colorbar(im2, ax=ax2)\n",
        "\n",
        "# Physics-Attention: M×M\n",
        "ax3 = axes[2]\n",
        "im3 = ax3.imshow(attn_matrix, cmap='Greens')\n",
        "ax3.set_title(f'Physics-Attention\\n({M}×{M} = {M*M} ops)', fontsize=11)\n",
        "ax3.set_xlabel('Key slices')\n",
        "ax3.set_ylabel('Query slices')\n",
        "plt.colorbar(im3, ax=ax3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"Cost reduction: {N*N:,} → {M*M} = {N*N // (M*M):,}x fewer attention operations!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. How Mesh Points Get Distributed to Slices\n",
        "\n",
        "Let's visualize exactly how mesh points get assigned to slices. Each point gets a **soft assignment weight** to each slice (values sum to 1). The point \"belongs\" most strongly to the slice with highest weight.\n",
        "\n",
        "### Step-by-Step with M=3 Slices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Detailed visualization with M=3 slices\n",
        "M_demo = 3\n",
        "np.random.seed(123)  # For reproducibility\n",
        "\n",
        "# Step 1: Compute slice assignment weights\n",
        "W_demo = np.random.randn(C, M_demo) * 0.8\n",
        "slice_logits = features @ W_demo\n",
        "slice_weights = softmax(slice_logits, axis=1)  # Shape: (N, 3)\n",
        "dominant_slice = np.argmax(slice_weights, axis=1)\n",
        "\n",
        "# Count points per slice\n",
        "slice_colors = ['#e41a1c', '#377eb8', '#4daf4a']  # Red, Blue, Green\n",
        "slice_names = ['Slice 0 (Red)', 'Slice 1 (Blue)', 'Slice 2 (Green)']\n",
        "counts = [np.sum(dominant_slice == i) for i in range(M_demo)]\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(f\"SLICE ASSIGNMENT SUMMARY (M={M_demo} slices)\")\n",
        "print(\"=\"*60)\n",
        "for i, (name, count) in enumerate(zip(slice_names, counts)):\n",
        "    pct = 100 * count / N\n",
        "    print(f\"  {name}: {count:,} points ({pct:.1f}%)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Create comprehensive visualization\n",
        "fig = plt.figure(figsize=(16, 10))\n",
        "\n",
        "# Row 1: Show individual slices\n",
        "for i in range(M_demo):\n",
        "    ax = fig.add_subplot(2, 4, i+1)\n",
        "    mask = dominant_slice == i\n",
        "    \n",
        "    # Plot all points faded\n",
        "    ax.scatter(coords[:, 0], coords[:, 1], c='lightgray', s=3, alpha=0.3)\n",
        "    # Highlight this slice's points\n",
        "    ax.scatter(coords[mask, 0], coords[mask, 1], c=slice_colors[i], s=8, alpha=0.8)\n",
        "    \n",
        "    ax.set_title(f'Slice {i}\\n({counts[i]:,} points)', fontsize=11, color=slice_colors[i])\n",
        "    ax.set_xlabel('x')\n",
        "    ax.set_ylabel('y')\n",
        "    ax.set_aspect('equal')\n",
        "\n",
        "# Row 1, Col 4: All slices combined\n",
        "ax_combined = fig.add_subplot(2, 4, 4)\n",
        "for i in range(M_demo):\n",
        "    mask = dominant_slice == i\n",
        "    ax_combined.scatter(coords[mask, 0], coords[mask, 1], \n",
        "                       c=slice_colors[i], s=6, alpha=0.7, label=f'Slice {i}')\n",
        "ax_combined.set_title('All 3 Slices Combined', fontsize=11)\n",
        "ax_combined.set_xlabel('x')\n",
        "ax_combined.set_ylabel('y')\n",
        "ax_combined.set_aspect('equal')\n",
        "ax_combined.legend(loc='upper right', fontsize=9)\n",
        "\n",
        "# Row 2, Col 1: Soft assignment weights heatmap\n",
        "ax_weights = fig.add_subplot(2, 4, 5)\n",
        "# Sort points by dominant slice for visualization\n",
        "sort_idx = np.lexsort((coords[np.arange(N), 0], dominant_slice))\n",
        "im = ax_weights.imshow(slice_weights[sort_idx].T, aspect='auto', cmap='YlOrRd',\n",
        "                       extent=[0, N, -0.5, M_demo-0.5])\n",
        "ax_weights.set_title('Soft Assignment Weights\\n(each column sums to 1)', fontsize=10)\n",
        "ax_weights.set_xlabel(f'Mesh Points (sorted, N={N})')\n",
        "ax_weights.set_ylabel('Slice ID')\n",
        "ax_weights.set_yticks([0, 1, 2])\n",
        "plt.colorbar(im, ax=ax_weights, label='Weight')\n",
        "\n",
        "# Row 2, Col 2: Bar chart of distribution\n",
        "ax_bar = fig.add_subplot(2, 4, 6)\n",
        "bars = ax_bar.bar(range(M_demo), counts, color=slice_colors, edgecolor='black')\n",
        "ax_bar.set_xlabel('Slice ID')\n",
        "ax_bar.set_ylabel('Number of Points')\n",
        "ax_bar.set_title('Points per Slice', fontsize=11)\n",
        "ax_bar.set_xticks(range(M_demo))\n",
        "for bar, count in zip(bars, counts):\n",
        "    ax_bar.annotate(f'{count}', xy=(bar.get_x() + bar.get_width()/2, bar.get_height()),\n",
        "                   ha='center', va='bottom', fontsize=10)\n",
        "\n",
        "# Row 2, Col 3-4: Example point assignment\n",
        "ax_example = fig.add_subplot(2, 4, 7)\n",
        "# Pick 5 example points (one from each region)\n",
        "example_indices = np.random.choice(N, 5, replace=False)\n",
        "example_weights = slice_weights[example_indices]\n",
        "\n",
        "x_pos = np.arange(5)\n",
        "width = 0.25\n",
        "for i in range(M_demo):\n",
        "    ax_example.bar(x_pos + i*width, example_weights[:, i], width, \n",
        "                  color=slice_colors[i], label=f'Slice {i}', alpha=0.8)\n",
        "ax_example.set_xlabel('Example Points')\n",
        "ax_example.set_ylabel('Assignment Weight')\n",
        "ax_example.set_title('Soft Weights for 5 Sample Points\\n(each point sums to 1)', fontsize=10)\n",
        "ax_example.set_xticks(x_pos + width)\n",
        "ax_example.set_xticklabels([f'P{i}' for i in range(5)])\n",
        "ax_example.legend(fontsize=8)\n",
        "ax_example.set_ylim(0, 1)\n",
        "\n",
        "# Row 2, Col 4: The resulting M×M attention\n",
        "ax_attn = fig.add_subplot(2, 4, 8)\n",
        "phys_attn = softmax(np.random.randn(M_demo, M_demo), axis=1)\n",
        "im_attn = ax_attn.imshow(phys_attn, cmap='Greens', vmin=0, vmax=1)\n",
        "ax_attn.set_title(f'Physics-Attention Matrix\\n(only {M_demo}×{M_demo}={M_demo**2} ops!)', fontsize=10)\n",
        "ax_attn.set_xlabel('Key Slice')\n",
        "ax_attn.set_ylabel('Query Slice')\n",
        "ax_attn.set_xticks(range(M_demo))\n",
        "ax_attn.set_yticks(range(M_demo))\n",
        "plt.colorbar(im_attn, ax=ax_attn)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\n✓ Instead of {N}×{N}={N*N:,} attention ops, we only need {M_demo}×{M_demo}={M_demo**2}!\")\n",
        "print(f\"✓ Cost reduction: {N*N // M_demo**2:,}x fewer operations\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Effect of Different Slice Counts (M)\n",
        "\n",
        "More slices = finer grouping but higher cost. Typical values: M=8 to M=64."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare M=4, M=8, M=16 slice partitioning\n",
        "slice_configs = [4, 8, 16]\n",
        "fig_compare, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
        "\n",
        "for idx, num_slices in enumerate(slice_configs):\n",
        "    ax = axes[idx]\n",
        "    np.random.seed(42 + idx)  # Different seed for variety\n",
        "    \n",
        "    # Compute slice assignments\n",
        "    W = np.random.randn(C, num_slices) * 0.6\n",
        "    logits = features @ W\n",
        "    weights = softmax(logits, axis=1)\n",
        "    dominant_slice = np.argmax(weights, axis=1)\n",
        "    \n",
        "    # Plot mesh colored by slice\n",
        "    scatter = ax.scatter(coords[:, 0], coords[:, 1], c=dominant_slice, \n",
        "                        cmap='tab10' if num_slices <= 10 else 'tab20',\n",
        "                        s=6, alpha=0.7)\n",
        "    \n",
        "    # Calculate cost reduction\n",
        "    cost_reduction = N*N // (num_slices**2)\n",
        "    ax.set_title(f'M = {num_slices} slices\\nAttention: {num_slices}×{num_slices}={num_slices**2} ops\\n({cost_reduction:,}x cheaper)', \n",
        "                fontsize=10)\n",
        "    ax.set_xlabel('x')\n",
        "    ax.set_ylabel('y')\n",
        "    ax.set_aspect('equal')\n",
        "    plt.colorbar(scatter, ax=ax, label='Slice ID', shrink=0.8)\n",
        "\n",
        "plt.suptitle('Trade-off: More Slices = Finer Resolution but Higher Cost', fontsize=12, y=1.02)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nTypical M values in Transolver: 8-64 (paper uses M=32 or M=64)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "| Aspect | Standard Attention | Physics-Attention |\n",
        "|--------|-------------------|-------------------|\n",
        "| **Complexity** | O(N²) — expensive! | O(N·M) — efficient! |\n",
        "| **Attention matrix** | N×N | M×M (M≈64) |\n",
        "| **Grouping** | All-to-all | Learned slices |\n",
        "\n",
        "**Key Takeaway:** Physics-Attention reduces cost by grouping mesh points into M learned \"slices\" and performing attention between these compressed representations.\n",
        "\n",
        "**Next:** Notebook 2 shows the full Transolver architecture in PyTorch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
